{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4396e0",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0897a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe4d66",
   "metadata": {},
   "source": [
    "# Load BART Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a7813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a61fb234d434adc8256ce7fee1a09c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31af04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "This message is similar to messages that were identified as spam in the past.\n"
     ]
    }
   ],
   "source": [
    "text = \"This message is similar to messages that were identified as spam in the past.\"\n",
    "print(\"Original Text:\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2cf6d",
   "metadata": {},
   "source": [
    "# Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de87aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer(text,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63add18",
   "metadata": {},
   "source": [
    "# Noise Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a745c",
   "metadata": {},
   "source": [
    "## Token Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b399796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_m(text,mask_prob=0.3):\n",
    "    words = text.split()\n",
    "    masked=[]\n",
    "\n",
    "    for w in words:\n",
    "        if random.random() < mask_prob:\n",
    "            masked.append(tokenizer.mask_token)\n",
    "        else:\n",
    "            masked.append(w)\n",
    "\n",
    "    return \" \".join(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c90d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mask> message <mask> similar to messages <mask> were identified as spam in the past.\n"
     ]
    }
   ],
   "source": [
    "print(token_m(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec73501",
   "metadata": {},
   "source": [
    "## Token Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab66bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_deletion(text, delete_prob=0.3):\n",
    "    words = text.split()\n",
    "    kept = []\n",
    "    \n",
    "    for w in words:\n",
    "        if random.random() > delete_prob:\n",
    "            kept.append(w)\n",
    "    return \" \".join(kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8ce3566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message is to messages that identified spam the past.\n"
     ]
    }
   ],
   "source": [
    "print(token_deletion(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e6e2e",
   "metadata": {},
   "source": [
    "## Sentence Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ac65748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_permutation(text):\n",
    "    sentences = text.split(\". \")\n",
    "    random.shuffle(sentences)\n",
    "    return \". \".join(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18581dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It uses noise. It reconstructs text.. BART is powerful\n"
     ]
    }
   ],
   "source": [
    "multi_sentence = \"BART is powerful. It uses noise. It reconstructs text.\"\n",
    "print(sentence_permutation(multi_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0f5f3",
   "metadata": {},
   "source": [
    "## Span Infilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "396a0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_fil(text,span_len=2):\n",
    "    words = text.split()\n",
    "\n",
    "    if len(words) <= span_len:\n",
    "        return text\n",
    "\n",
    "    start = random.randint(0,len(words)-span_len)\n",
    "    corrupted = (\n",
    "        words[:start] + [tokenizer.mask_token] + words[start + span_len:]\n",
    "\n",
    "    )\n",
    "\n",
    "    return \" \".join(corrupted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c81a0e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This message is similar to <mask> identified as spam in the past.\n"
     ]
    }
   ],
   "source": [
    "print(span_fil(text, span_len=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182b147",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "936debb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: This message is similar to messages that were identified as spam in the past.\n",
      "Noisy: This message is similar to messages that <mask> spam in the past.\n"
     ]
    }
   ],
   "source": [
    "noisy_text = span_fil(text, span_len=3)\n",
    "print(\"original text:\", text)\n",
    "print(\"Noisy:\", noisy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c879e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed: This message is similar to messages that have been sent as spam in the past.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(noisy_text,return_tensors=\"pt\")\n",
    "output = model.generate(**inputs,max_length=50)\n",
    "\n",
    "print(\"Reconstructed:\", tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

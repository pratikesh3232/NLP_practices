{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b55ef17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20a59b05",
   "metadata": {},
   "source": [
    "# Mini Project — Fine-Tuning NER on a Custom Small Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281a28d",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9741a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4c91f",
   "metadata": {},
   "source": [
    "# Custom NER Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cec243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    {\n",
    "        \"tokens\": [\"Iron\", \"Man\", \"is\", \"played\", \"by\", \"Robert\", \"Downey\", \"Jr.\"],\n",
    "        \"ner_tags\": [\n",
    "            \"B-CHARACTER\", \"I-CHARACTER\", \"O\", \"O\", \"O\",\n",
    "            \"B-ACTOR\", \"I-ACTOR\", \"I-ACTOR\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"Batman\", \"appears\", \"in\", \"The\", \"Dark\", \"Knight\"],\n",
    "        \"ner_tags\": [\n",
    "            \"B-CHARACTER\", \"O\", \"O\",\n",
    "            \"B-MOVIE\", \"I-MOVIE\", \"I-MOVIE\"\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544a1e7",
   "metadata": {},
   "source": [
    "# Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deeebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"O\",\n",
    "    \"B-CHARACTER\", \"I-CHARACTER\",\n",
    "    \"B-ACTOR\", \"I-ACTOR\",\n",
    "    \"B-MOVIE\", \"I-MOVIE\"\n",
    "]\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92a001",
   "metadata": {},
   "source": [
    "# Load Tokenizer & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9630763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180229e",
   "metadata": {},
   "source": [
    "# Tokenization + Label Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7647e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    word_ids = tokenized.word_ids()\n",
    "    previous_word_idx = None\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(label2id[example[\"ner_tags\"][word_idx]])\n",
    "        else:\n",
    "            labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94558d",
   "metadata": {},
   "source": [
    "# Convert to HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec4cd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfa2c4b2f1241d1ba84f76103e53d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dataset = Dataset.from_list(dataset)\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde1e4f",
   "metadata": {},
   "source": [
    "# Data Collator (CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08eb3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2703e1",
   "metadata": {},
   "source": [
    "# Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3205aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"   # disables wandb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb032e4",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "288d8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e034763",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128f5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.323600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=1.3235636711120606, metrics={'train_runtime': 5.5083, 'train_samples_per_second': 1.815, 'train_steps_per_second': 0.908, 'total_flos': 61244195760.0, 'train_loss': 1.3235636711120606, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863ec6a",
   "metadata": {},
   "source": [
    "# Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf007f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iron Man → CHARACTER\n",
      "Robert Down → ACTOR\n",
      "Jr → ACTOR\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "text = \"Iron Man is played by Robert Downey Jr.\"\n",
    "results = ner_pipeline(text)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['word']} → {r['entity_group']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
